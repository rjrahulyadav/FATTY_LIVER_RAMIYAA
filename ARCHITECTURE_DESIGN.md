# Architecture & System Design Documentation

## ğŸ—ï¸ SIAMESE NEURAL NETWORK ARCHITECTURE

### Network Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SIAMESE NETWORK ARCHITECTURE                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT: Paired Images (Same Class or Different Class)
        â†“                                    â†“
    [Image 1]                          [Image 2]
   224Ã—224 RGB                        224Ã—224 RGB
        â†“                                    â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                                          â”‚
     â”‚    SHARED ENCODER: ResNet-50             â”‚
     â”‚  (Pre-trained on ImageNet)               â”‚
     â”‚                                          â”‚
     â”‚  Input: 224Ã—224Ã—3                        â”‚
     â”‚  Output: 2048-dim features               â”‚
     â”‚                                          â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“                                  â†“
       [fâ‚ âˆˆ â„Â²â°â´â¸]                    [fâ‚‚ âˆˆ â„Â²â°â´â¸]
          â†“                                  â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                        â”‚                         â”‚
     â–¼                        â–¼                         â–¼
[Projection Head]    [Projection Head]      [Classification Head]
[2048 â†’ 512 â†’ 128]   [2048 â†’ 512 â†’ 128]     [2048 â†’ 5]
     â†“                        â†“                         â†“
[Embedding zâ‚]        [Embedding zâ‚‚]           [Logits]
 128-dim               128-dim                  5 classes
     â†“                        â†“                         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       [Classification]
  â”‚  CONTRASTIVE LOSS (NT-Xent)     â”‚
  â”‚  â”€ Maximize similarity(zâ‚, zâ‚‚)  â”‚
  â”‚    if same class                â”‚       CROSS-ENTROPY LOSS
  â”‚  â”€ Minimize similarity if       â”‚       â”€ Minimize prediction
  â”‚    different class              â”‚         error on labels
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“
    [Loss Backprop]
          â†“
   [Gradient Update]


TWO FORWARD MODES:

Mode 1: CONTRASTIVE LEARNING (Pre-training)
  forward(image1, image2)
  â†’ returns (proj1, proj2)
  â†’ uses NTXentLoss
  â†’ learns feature representations

Mode 2: CLASSIFICATION (Fine-tuning)
  forward(image)
  â†’ returns logits
  â†’ uses CrossEntropyLoss
  â†’ predicts disease class
```

---

## ğŸ“Š DATA FLOW PIPELINE

### Training Data Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATASET LOADING                         â”‚
â”‚                                                            â”‚
â”‚  .mat File (MATLAB)              or  Image Folders        â”‚
â”‚  (10,500 augmented images)           (Normal/, Grade-I/)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FAT PERCENTAGE TO CLASS MAPPING               â”‚
â”‚                                                            â”‚
â”‚  fat_val < 5%          â†’ Class 0 (Normal)                 â”‚
â”‚  5% â‰¤ fat_val â‰¤ 35%    â†’ Class 1 (Grade-I)               â”‚
â”‚  35% < fat_val â‰¤ 65%   â†’ Class 2 (Grade-II)              â”‚
â”‚  fat_val > 65%         â†’ Class 3 (Grade-III)             â”‚
â”‚  class_val == CLD      â†’ Class 4 (CLD)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           TRAIN/VAL/TEST SPLIT (80-10-10)                 â”‚
â”‚                                                            â”‚
â”‚  Training Set (80%)  â†’ For model learning                 â”‚
â”‚  Validation Set (10%) â†’ For hyperparameter tuning         â”‚
â”‚  Test Set (10%)      â†’ For final evaluation              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               IMAGE AUGMENTATION PIPELINE                  â”‚
â”‚                                                            â”‚
â”‚  Input: Raw image                                         â”‚
â”‚    â†“                                                      â”‚
â”‚  Resize â†’ 224Ã—224 pixels                                 â”‚
â”‚    â†“                                                      â”‚
â”‚  Rotation â†’ Random Â±20Â° rotation                         â”‚
â”‚    â†“                                                      â”‚
â”‚  Affine â†’ Random shear (10Â°) + zoom (0.8-1.2x)          â”‚
â”‚    â†“                                                      â”‚
â”‚  Flip â†’ Horizontal (50%) + Vertical (50%)                â”‚
â”‚    â†“                                                      â”‚
â”‚  ColorJitter â†’ Brightness, Contrast, Saturation         â”‚
â”‚    â†“                                                      â”‚
â”‚  Normalize â†’ ImageNet stats                              â”‚
â”‚    â†“                                                      â”‚
â”‚  ToTensor â†’ Convert to PyTorch tensor                    â”‚
â”‚    â†“                                                      â”‚
â”‚  Output: Augmented 224Ã—224Ã—3 tensor                      â”‚
â”‚                                                            â”‚
â”‚  Mean: [0.485, 0.456, 0.406]                             â”‚
â”‚  Std:  [0.229, 0.224, 0.225]                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BATCH CREATION & LOADING                      â”‚
â”‚                                                            â”‚
â”‚  Batch Size: 32 (configurable)                            â”‚
â”‚  Shuffle: True (training), False (val/test)              â”‚
â”‚  Num Workers: 4 (parallel loading)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                    [Ready for Training]
```

---

## ğŸ”„ TWO-STAGE TRAINING PIPELINE

### Stage 1: Contrastive Pre-Training (Self-Supervised)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CONTRASTIVE PRE-TRAINING (Self-Supervised)       â”‚
â”‚              Epochs: 20 (default)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input Batch:
    [Image 1, Image 2, ..., Image 32]
            â†“
    Augment each image differently
    (Same image, different augmentations)
            â†“
    Forward through Siamese Network
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Output: Embedding Pairs                â”‚
    â”‚  (zâ‚â‚, zâ‚â‚‚), (zâ‚‚â‚, zâ‚‚â‚‚), ..., (zâ‚ƒâ‚‚â‚, zâ‚ƒâ‚‚â‚‚) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  NT-Xent Loss Computation               â”‚
    â”‚                                         â”‚
    â”‚  Loss = -(1/B) Î£ log[                   â”‚
    â”‚      exp(sim(z_i, z_i+) / Ï„) /          â”‚
    â”‚      (Î£ exp(sim(z_i, z_k) / Ï„))        â”‚
    â”‚    ]                                    â”‚
    â”‚                                         â”‚
    â”‚  Where:                                 â”‚
    â”‚  - sim() = cosine similarity             â”‚
    â”‚  - Ï„ = temperature = 0.5                â”‚
    â”‚  - B = batch size = 32                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    Backpropagation
            â†“
    Gradient Clipping (max_norm=1.0)
            â†“
    Adam Optimizer Step
            â†“
    Update encoder & projection head weights
            â†“
    Repeat for 20 epochs


Output: Pre-trained encoder with good feature representations
```

### Stage 2: Classification Training (Supervised)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         CLASSIFICATION TRAINING (Supervised)             â”‚
â”‚              Epochs: 50 (default)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Training Loop:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Input Batch: [Images, Labels]          â”‚
    â”‚  Labels: [0,1,2,3,4] (5 classes)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    Forward Pass:
    Image â†’ ResNet-50 Encoder â†’ Classifier
            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Output: Class Logits                   â”‚
    â”‚  [batch_size, 5]                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    Cross-Entropy Loss:
    Loss = -(1/B) Î£ log[exp(z_ci) / Î£ exp(z_j)]
            â†“
    Backpropagation
            â†“
    Gradient Clipping (max_norm=1.0)
            â†“
    Adam Optimizer Step
            â†“
    Update encoder & classifier weights


Validation Loop (Each Epoch):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Evaluate on validation set              â”‚
    â”‚  Compute validation accuracy             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    If validation_acc > best_acc:
        Save model checkpoint
        best_acc = validation_acc
            â†“
    Continue training or early stop


Output: Best trained model (lowest validation loss)
        Saved as: best_model.pth
```

---

## ğŸ¯ CLASSIFICATION CATEGORIES & MAPPING

### Fat Percentage Classification System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     FAT ACCUMULATION LEVELS & CLINICAL GRADES       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Class 0: NORMAL
â”œâ”€ Fat Content: < 5%
â”œâ”€ Clinical Status: Healthy liver
â”œâ”€ Ultrasound Appearance: Normal echogenicity
â””â”€ Output Index: 0

Class 1: GRADE-I (MILD STEATOSIS)
â”œâ”€ Fat Content: 5-35%
â”œâ”€ Clinical Status: Mild fatty infiltration
â”œâ”€ Ultrasound Appearance: Slightly increased echogenicity
â””â”€ Output Index: 1

Class 2: GRADE-II (MODERATE STEATOSIS)
â”œâ”€ Fat Content: 35-65%
â”œâ”€ Clinical Status: Moderate fat accumulation
â”œâ”€ Ultrasound Appearance: Increased echogenicity with vessel blurring
â””â”€ Output Index: 2

Class 3: GRADE-III (SEVERE STEATOSIS)
â”œâ”€ Fat Content: > 65%
â”œâ”€ Clinical Status: Severe fat accumulation
â”œâ”€ Ultrasound Appearance: Strong echogenicity, poor vessel visualization
â””â”€ Output Index: 3

Class 4: CLD (CHRONIC LIVER DISEASE)
â”œâ”€ Characteristics: Cirrhosis, fibrosis, scarring
â”œâ”€ Clinical Status: Advanced liver damage
â”œâ”€ Ultrasound Appearance: Heterogeneous echogenicity, nodular surface
â””â”€ Output Index: 4


MODEL OUTPUT STRUCTURE:

Softmax Output:     [pâ‚€, pâ‚, pâ‚‚, pâ‚ƒ, pâ‚„]
Where:
  pâ‚€ = P(Normal)
  pâ‚ = P(Grade-I)
  pâ‚‚ = P(Grade-II)
  pâ‚ƒ = P(Grade-III)
  pâ‚„ = P(CLD)

Prediction = argmax(pâ‚€, pâ‚, pâ‚‚, pâ‚ƒ, pâ‚„)

Confidence = max(pâ‚€, pâ‚, pâ‚‚, pâ‚ƒ, pâ‚„)
```

---

## ğŸ“ˆ EVALUATION METRICS FRAMEWORK

### Performance Metrics Calculation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EVALUATION METRICS PIPELINE               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Model Inference on Test Set:
    Model(test_images) â†’ predictions
            â†“
    Softmax â†’ probabilities
            â†“
    argmax â†’ class predictions


METRIC 1: BINARY CLASSIFICATION ACCURACY
â”œâ”€ Definition: Normal (0) vs Abnormal (1-4)
â”œâ”€ Formula: Accuracy = (TP + TN) / (TP + TN + FP + FN)
â”œâ”€ Target: â‰¥ 99.90%
â””â”€ Computation:
    binary_pred = (pred > 0).astype(int)
    binary_true = (true > 0).astype(int)
    accuracy = mean(binary_pred == binary_true)


METRIC 2: MULTI-CLASS ACCURACY
â”œâ”€ Definition: Across all 5 classes
â”œâ”€ Formula: Accuracy = (Correct Predictions) / (Total Predictions)
â”œâ”€ Target: â‰¥ 99.77%
â””â”€ Computation: accuracy = mean(pred == true)


METRIC 3: PER-CLASS METRICS
â”œâ”€ Precision: TP / (TP + FP)  [How many predicted positives were correct]
â”œâ”€ Recall: TP / (TP + FN)     [How many actual positives were found]
â”œâ”€ F1-Score: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
â””â”€ For each class in [Normal, Grade-I, Grade-II, Grade-III, CLD]


METRIC 4: CONFUSION MATRIX
â”œâ”€ Dimensions: 5Ã—5 matrix
â”œâ”€ Element [i,j]: Count of class i predicted as class j
â”œâ”€ Diagonal elements: Correct predictions
â””â”€ Off-diagonal elements: Misclassifications


METRIC 5: ROC-AUC SCORE
â”œâ”€ Binary ROC-AUC: Target â‰¥ 0.990
â”‚  â””â”€ Measures: Normal vs Abnormal discrimination
â”‚
â”œâ”€ Multi-class ROC-AUC: Target â‰¥ 0.999
â”‚  â””â”€ Method: One-vs-Rest (OvR) approach
â”‚  â””â”€ Computes: AUC for each class vs all others
â”‚  â””â”€ Returns: Macro-averaged AUC
â””â”€ Formula: Area under ROC curve
    (Sensitivity vs 1-Specificity at various thresholds)


METRIC 6: SENSITIVITY & SPECIFICITY (Per Class)
â”œâ”€ Sensitivity = TP / (TP + FN)        [True Positive Rate]
â”œâ”€ Specificity = TN / (TN + FP)        [True Negative Rate]
â””â”€ Derived from confusion matrix


OUTPUT REPORT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classification Report:              â”‚
â”‚ â”€ Precision (per class)             â”‚
â”‚ â”€ Recall (per class)                â”‚
â”‚ â”€ F1-Score (per class)              â”‚
â”‚ â”€ Support (samples per class)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Overall Metrics:                    â”‚
â”‚ â”€ Binary Accuracy                   â”‚
â”‚ â”€ Multi-class Accuracy              â”‚
â”‚ â”€ Binary ROC-AUC                    â”‚
â”‚ â”€ Multi-class ROC-AUC               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Confusion Matrix:                   â”‚
â”‚ â”€ 5Ã—5 prediction breakdown          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”’ ROBUSTNESS & ERROR HANDLING

### Numerical Stability Measures

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        NUMERICAL STABILITY & ERROR HANDLING           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. GRADIENT CLIPPING
   â”œâ”€ Max Norm: 1.0
   â”œâ”€ Applied after: Backpropagation
   â”œâ”€ Purpose: Prevent gradient explosion
   â””â”€ Code: torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)


2. NaN/Inf DETECTION
   â”œâ”€ Check in projections: torch.isnan(proj1).any()
   â”œâ”€ Check in outputs: torch.isinf(outputs).any()
   â”œâ”€ Check in loss: torch.isnan(loss) or loss.item() > 1e6
   â”œâ”€ Action: Skip batch if detected
   â””â”€ Purpose: Catch numerical issues early


3. LOSS VALUE VALIDATION
   â”œâ”€ Check: loss.item() > 1e6 (indicates instability)
   â”œâ”€ Action: Skip batch to prevent divergence
   â””â”€ Logged: Warning messages for monitoring


4. CHECKPOINT VALIDATION
   â”œâ”€ Before saving: Check for NaNs in state dict
   â”œâ”€ Verify: All parameters are finite
   â”œâ”€ Action: Only save valid checkpoints
   â””â”€ Purpose: Prevent corrupted models


5. BATCH HANDLING
   â”œâ”€ Check: images.shape[0] == 0
   â”œâ”€ Action: Skip empty batches
   â””â”€ Purpose: Handle edge cases gracefully


6. TEMPERATURE SCALING (NTXentLoss)
   â”œâ”€ Minimum: 0.01 (prevent division by zero)
   â”œâ”€ Purpose: Stabilize contrastive loss
   â””â”€ Range: 0.01 to 0.5 (adjustable)


STABILITY GUARANTEES:
  âœ“ No gradient explosion (clipping)
  âœ“ No numerical underflow/overflow (validation)
  âœ“ Graceful error handling (skip problematic batches)
  âœ“ Valid checkpoint persistence (pre-save validation)
```

---

## ğŸ“ PROJECT STRUCTURE MAPPING

```
fatty-liver-classification/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ siamese_net.py              # âœ… Siamese network architecture
â”‚       â”œâ”€ SiameseNetwork class
â”‚       â”œâ”€ ResNet-50 encoder (pre-trained)
â”‚       â”œâ”€ Projection head (2048 â†’ 512 â†’ 128)
â”‚       â”œâ”€ Classification head (2048 â†’ 5)
â”‚       â””â”€ Dual forward modes (contrastive & classification)
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ data_loader.py               # âœ… Data loading & augmentation
â”‚       â”œâ”€ FattyLiverDataset class
â”‚       â”œâ”€ ContrastiveDataset class
â”‚       â”œâ”€ .mat file loading
â”‚       â”œâ”€ Augmentation pipeline (7 techniques)
â”‚       â”œâ”€ Train/val/test splitting (80-10-10)
â”‚       â””â”€ Class mapping (fat % â†’ class)
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ losses.py                    # âœ… Loss functions
â”‚       â”œâ”€ ContrastiveLoss class
â”‚       â”œâ”€ NTXentLoss class
â”‚       â”œâ”€ Temperature scaling
â”‚       â””â”€ Normalization
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                     # âœ… Two-stage training
â”‚   â”‚   â”œâ”€ train_contrastive() [Stage 1]
â”‚   â”‚   â”œâ”€ train_classification() [Stage 2]
â”‚   â”‚   â”œâ”€ Gradient clipping
â”‚   â”‚   â”œâ”€ NaN detection
â”‚   â”‚   â””â”€ Best model checkpointing
â”‚   â”‚
â”‚   â””â”€â”€ evaluate.py                  # âœ… Comprehensive evaluation
â”‚       â”œâ”€ evaluate_model()
â”‚       â”œâ”€ Binary accuracy
â”‚       â”œâ”€ Multi-class accuracy
â”‚       â”œâ”€ ROC-AUC scores
â”‚       â”œâ”€ Classification report
â”‚       â””â”€ Confusion matrix
â”‚
â”œâ”€â”€ infer.py                         # âœ… Single image inference
â”‚   â”œâ”€ infer_image()
â”‚   â”œâ”€ .mat file image loading
â”‚   â””â”€ Probability output
â”‚
â”œâ”€â”€ main.py                          # âœ… CLI entry point
â”‚   â”œâ”€ download_data() [instructions]
â”‚   â”œâ”€ train_model() [training]
â”‚   â””â”€ evaluate_model() [evaluation]
â”‚
â”œâ”€â”€ best_model.pth                   # Model checkpoint (saved)
â”œâ”€â”€ best_model.pth.backup            # Backup checkpoint
â”‚
â”œâ”€â”€ data/                            # Dataset directory (to download)
â”‚   â””â”€â”€ dataset_liver_bmodes_steatosis_assessment_IJCARS.mat
â”‚
â”œâ”€â”€ README.md                        # Project documentation
â”œâ”€â”€ TODO.md                          # Task tracking
â”œâ”€â”€ PROJECT_COMPLIANCE_REPORT.md     # Compliance verification
â””â”€â”€ COMPLIANCE_CHECKLIST.md          # Quick reference checklist


KEY FILES BY REQUIREMENT:

Architecture:
  â†’ models/siamese_net.py

Data Processing:
  â†’ src/data_loader.py

Training:
  â†’ scripts/train.py
  â†’ utils/losses.py

Evaluation:
  â†’ scripts/evaluate.py

Inference:
  â†’ infer.py

Entry Point:
  â†’ main.py
```

---

## ğŸ”— CONTROL FLOW DIAGRAMS

### User Interaction Flow

```
USER COMMANDS:
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       python main.py [COMMAND]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
        â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                â†“          â†“          â†“
   download_data    train        evaluate   (inference)
        â†“                â†“          â†“
    Manual DL        scripts/   scripts/
    from Kaggle      train.py   evaluate.py
                        â†“          â†“
                    [Training]  [Evaluation]
                        â†“          â†“
                    best_model  Metrics
                     .pth       (Accuracy,
                                 AUC, etc)
```

### Internal Execution Flow (Training)

```
TRAINING EXECUTION:

python main.py train
    â†“
main.py::train_model()
    â†“
subprocess: scripts/train.py
    â†“
main()
    â”œâ”€ Parse arguments
    â”œâ”€ Set device (CUDA or CPU)
    â”œâ”€ Load data
    â”‚  â””â”€ get_data_loaders() / get_contrastive_data_loader()
    â”œâ”€ Create model
    â”‚  â””â”€ SiameseNetwork().to(device)
    â”‚
    â”œâ”€ STAGE 1: Contrastive Pre-training
    â”‚  â”œâ”€ train_contrastive()
    â”‚  â”œâ”€ Use: NTXentLoss
    â”‚  â”œâ”€ Epochs: 20
    â”‚  â””â”€ Output: Pre-trained encoder
    â”‚
    â”œâ”€ STAGE 2: Classification Training
    â”‚  â”œâ”€ train_classification()
    â”‚  â”œâ”€ Use: CrossEntropyLoss
    â”‚  â”œâ”€ Epochs: 50
    â”‚  â”œâ”€ Validation: Each epoch
    â”‚  â”œâ”€ Best model: Saved
    â”‚  â””â”€ Output: best_model.pth
    â”‚
    â””â”€ Checkpoint validation
       â””â”€ Verify no NaNs
```

---

## âš¡ PERFORMANCE CHARACTERISTICS

### Computational Requirements

```
Training:
â”œâ”€ GPU Memory: ~4-6 GB (batch_size=32)
â”œâ”€ Training Time: ~2-4 hours (depending on hardware)
â”œâ”€ Batch Processing: 32 images/batch
â””â”€ Total Epochs: 70 (20 contrastive + 50 classification)

Inference:
â”œâ”€ Single Image: ~50-100 ms
â”œâ”€ Throughput: 10-20 images/second (batch processing)
â””â”€ Model Size: ~100 MB (ResNet-50 checkpoint)

Evaluation:
â”œâ”€ Test Set Evaluation: ~5-10 minutes
â””â”€ Metrics Computation: Real-time
```

---

## ğŸ“Š SUMMARY

This document provides comprehensive technical documentation of the Fatty Liver Classification project architecture and implementation, validating all requirements across:

- âœ… **Architecture:** Siamese network with ResNet-50
- âœ… **Data Processing:** Full augmentation pipeline
- âœ… **Training:** Two-stage self-supervised + supervised
- âœ… **Classification:** 5-class disease grading
- âœ… **Evaluation:** Complete metrics framework
- âœ… **Robustness:** Numerical stability & error handling

**All technical specifications are met and validated.**
